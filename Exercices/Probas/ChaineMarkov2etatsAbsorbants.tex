%-------------------------------------------------------------------------------
\subsubsection{Chaîne de Markov à 2 états absorbants}
%-------------------------------------------------------------------------------

On considère une chaîne de Markov $(X_n)_{n \geq 0}$ prenant ses valeurs dans $\{0, \dots \ell\}$, et on note $p(i, j)$ la probabilité de transition de $i$ à $j$. On suppose que 
$$
p_{0, 0} = p_{\ell, \ell} = 1 
$$
et que, pour tout $1 \leq i, j \leq \ell-1$, 
$$
p_{i, 0} = a > 0, \qquad p_{i, \ell} = b > 0, \qquad p_{i, j} \geq 0.
$$
On note de plus $T_{i, j}$ le temps d'atteinte de l'état $j$ à partir de l'état $i$:
$$
T_{i, j} = \min\{n: X_n = j \mid X_0 = i\}.
$$

\begin{enumerate}
  \item Donner la matrice de transition et tracer le graphe de transition de cette chaîne de Markov.
  \solution{
  $$
  P = \left(\begin{array}{c|ccc|c}
              1 & 0 & \cdots & 0 & 0 \\
              \hline
              a & p_{2, 2} & \cdots & p_{2, a-1} & b \\
              \vdots & \vdots &  & \vdots & \vdots \\
              a & p_{a-1, 2} & \cdots & p_{a-1, a-1} & b \\
              \hline
              0 & 0 & \cdots & 0 & 1
          \end{array}\right).
  $$}
  \item Quelles sont les classes de communication de cette chaîne ? Donner leur nature. Quels sont les comportements asymptotiques possibles de cette chaîne ?
  \solution{Les classes de communications sont 
  $$
  C_1 = \{0\}, \qquad C_2 = \{1, \dots, \ell-1\}, \qquad C_3 = \{\ell\}.
  $$
  $C_1$ et $C_3$ sont absorbantes, $C_2$ est transiente. La chaîne finit nécessairement par être absorbé en 0 ou $\ell$.}
  \item Soit $1 \leq i \leq \ell-1$, donner la probabilité que $X_{n+1}$ soit compris entre 1 et $\ell-1$ (inclus) sachant que $X_n = i$.
  \solution{Pour tout $1 \leq i \leq \ell-1$, on a $p_{i, 0} = a$ et $p_{i, \ell} = b$, donc
  $$
  \Pr\{1 \leq X_{n+1} \leq \ell-1 \mid X_n = i\}
  = \Pr\{X_{n+1} \neq 0 \text{ et } X_{n+1} \neq \ell\}
  = 1 -(a+b).
  $$}
  \item En déduire que, pour $1 \leq i \leq \ell-1$, en notant $c = a + b$, 
  $$
  \Pr\{T_{i, 0} = n\} = a (1 - c)^{n-1}, \qquad
  \Pr\{T_{i, \ell} = n\} = b (1 - c)^{n-1}.
  $$
  \solution{A chaque pas de temps, partant d'un état $1 \leq i \leq \ell-1$, la chaîne reste dans $\{1, \dots, \ell-1\}$ avec probabilité $1 - a - b = 1 - c$ et passe dans l'état 0 avec probabilité $a$. Pour atteindre l'état 0 depuis l'état $i$ en $n$ étapes, la chaîne doit rester $n-1$ fois dans $\{1, \dots, \ell-1\}$ (avec probabilité $(1-c)^{n-1}$) puis passer en 0 (avec probabilité $a$). \\
  L'autre résultat s'obtient par symétrie}
  \item Pour $1 \leq i \leq \ell-1$, on note maintenant $T_i$ le temps d’absorption (en 0 ou en $\ell$) : 
  $$
  T_i = \min(T_{i, 0}, T_{i, \ell}).
  $$
  Montrer que $T_i$ suit une loi géométrique $\Gcal(c)$ : $\Pr\{T_i = n\} = c (1 - c)^{n-1}$. \\
  En déduire son espérance.
  \solution{Il suffit de remarquer que l'événement d'absorption au temps $n$ s'écrit
  $$
  \{X_n \in \{0, \ell\}, X_0 = i\} = \{X_n = 0, X_0 = i\} \cup \{X_n = \ell, X_0 = i\}
  $$
  pour en déduire que 
  $$
  \Pr\{T_i = n\} = \Pr\{T_{i, 0} = n\} + \Pr\{T_{i, \ell} = n\} = (a + b) (1 - c)^{n-1}.
  $$
  De plus, en se souvenant que 
  $$
  \sum_{n \geq 1} n x^{n-1} 
  = \partial_x \sum_{n \geq 0} x^n 
  = \partial_x \frac{1}{1 - x}
  = (1 - x)^{-2}, 
  $$
  on obtient
  $$
  \Esp T_i = \sum_{n \geq 1} n c (1 - c)^{n-1} = c (1 - (1-c))^{-2} = 1/c.
  $$}
%   \item Montrer que, pour $1 \leq i \leq \ell-1$, 
%   $$
%   \Pr\{T_{i, 0} < n\} = \frac{a [1 - (1 - c)^{n-1}]}{c}.
%   $$
%   \solution{
%   \begin{align*}
%   \Pr\{T_{i, 0} < n\} 
%   & = \sum_{m =1}^{n-1} \Pr\{T_{i, 0} = m \} 
%   = a \sum_{m = 1}^{n-1} (1 - c)^{m-1} \\
%   & = \frac{a [1 - (1 - c)^{n-1}]}{1 - (1 - c)} 
%   = \frac{a [1 - (1 - c)^{n-1}]}{c}.
%   \end{align*}}
  \item Pour $1 \leq i \leq \ell-1$, calculer la probabilité que, partant de $X_0 = i$ la chaîne de Markov atteigne l'état 0 avant l'état $\ell$.
  \solution{La chaîne atteint 0 avant $\ell$ ssi $T_{i, 0} = T_i$. On remarque que, pour tout $n \geq 1$, on a
  $$
  \Pr\{T_{i, 0} = n \mid T_i = n\}
  = \frac{\Pr\{T_{i, 0} = n, T_i = n\}}{\Pr\{T_i = n\} }
  = \frac{\Pr\{T_{i, 0} = n\}}{\Pr\{T_i = n\}}
  = \frac{a}c.
  $$
  On a donc
  $$
  \Pr\{T_{i, 0} = T_i\}
  = \sum_{n \geq 1} \Pr\{T_{i, 0} = n \mid T_i = n\} \Pr\{T_i = n\} 
  = \sum_{n \geq 1} \frac{a}c \Pr\{T_i = n\}
  = \frac{a}c.
  $$}
  \item Combien valent les espérances respectives de $T_{i, 0}$ et $T_{i, \ell}$ pour $1 \leq i \leq \ell-1$ ?
  \solution{Puisque $a > 0$ et $b > 0$, chacun des deux états absorbants peut ne jamais être atteint : 
  \begin{align*}
  \Pr\{T_{i, 0} & = +\infty\} = \Pr\{T_i = T_{i, \ell}\} = b/c > 0, \\
  \text{et} \qquad
  \Pr\{T_{i, \ell} & = +\infty\} = \Pr\{T_i = T_{i, 0}\} = a/c > 0
  \end{align*}
  donc
  $$
  \Esp T_{i, 0} = \Esp T_{i, \ell} = + \infty.
  $$}
\end{enumerate}
